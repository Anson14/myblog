<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>与主机上其他任务共享资源的分布式优化框架 - Layer 7</title>
    <meta charset="utf-8" />
    <meta name="author" content="Layer 3" />
    <meta name="description" content="The study note for infocomm 2019" />
    <meta name="keywords" content="Infocomm, Study, Network" />
    <link rel="stylesheet" href="/media/css/main.css" type="text/css">
    <link rel="stylesheet" href="/media/css/prettify.css" type="text/css">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="shortcut icon" href="/favicon-16x16.png" type="image/x-icon"
  </head>

  <body class="container">
    <div>
      <header class="masthead">
        <h1 class="masthead-title"><a href="/">Layer 7</a></h1>
        <p>Thanks for Layer 3</p>
        <ul>
          <li><a href="/blog/">Blog</a></li>
          <li><a href="/tags/">Tags</a></li>
          <!--
          <li><a href="/tags/">Tags</a></li>
          -->
          <li><a href="/about/">About</a></li>
          <li><a href="https://github.com/Anson14">GitHub</a></li>
          <li><a href="/rss.xml">RSS</a></li>
        </ul>
        <form method="get" id="searchform" action="//www.google.com/search">
          <input type="text" class="field" name="q" id="s" placeholder="Search">
          <input type="hidden" name="as_sitesearch" value="ansont.cn">
        </form>
      </header>
    </div>

<div>
<div class="post">
<h1 class="title">与主机上其他任务共享资源的分布式优化框架</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org8d78aca">介绍</a>
<ul>
<li><a href="#org6fc6bf0">分布式优化</a></li>
<li><a href="#org92e24bb">什么是次梯度 <b>subgrdient</b></a></li>
<li><a href="#orgc442247">符号规定：</a></li>
</ul>
</li>
<li><a href="#org81a8392">模型与算法</a>
<ul>
<li><a href="#org2dcd96b">问题模型</a></li>
<li><a href="#org91b3c28">算法</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org8d78aca" class="outline-2">
<h2 id="org8d78aca">介绍</h2>
<div class="outline-text-2" id="text-org8d78aca">
<p>
题目名为：A Flexible Distributed Optimization Framework for Service of Concurrent Tasks in
Processing Networks
</p>
</div>

<div id="outline-container-org6fc6bf0" class="outline-3">
<h3 id="org6fc6bf0">分布式优化</h3>
<div class="outline-text-3" id="text-org6fc6bf0">
<p>
让一群没有服务器指挥的节点，在仅和邻居通讯（类似于 P2P）的情况下达到整体最优解。需要分布式优化的原因自然是因为 CS 架构的优化模型存在缺点，比如单点故障等原因，参考知乎<a href="https://www.zhihu.com/question/59260302">刘家耿的回答</a>，给出一个简单的形式化的表达式：
\[
  \min_{x_i,\cdots,x_n} \sum_{i=1}^n f_i(x_i)
\]
</p>

<p>
上面的公示与常规的优化公示相对应，CS 架构的的优化公示中的 x 是全局统一的，存储在中心 server 上，而分布式优化的 x 则存储在每一个 client 上，这里再借用下上面的回答中的一个流程进一步的阐述分布式优化：
</p>
<div class="org-src-container">
<pre class="src src-english">for each node i, simultaneously
*repeat*
    do gradient updates with own data;
    regularly exchange some information with neighbors;
    combine information according to some policy;
*until* reach consensus and optimaticaly
</pre>
</div>

<p>
文章里描述的是，可以为机器学习和信号处理提供使用内部网络连接的处理通过间歇性通信来完成全局最优目标的方法。目前的很多分布式化算法假设所有的处理器都存储了相关数据，但实际上是很多全局最优任务是运行在共享资源的主机上的，所以需要提出一种能够灵活的和其他任务共享<b>资源</b>的分布式优化算法。
</p>

<p>
Here is a summary of classic and novel <b>Distributed Optimization</b> 
</p>
<blockquote>
<p>
One of the pioneering works on distributed optimization was Tsitsiklis et al.’s
work [22]. Since then, several types of methods have been proposed in this area,
such as distributed subgradient descent (DSD) [8], [14], distributed dual
averaging [4], [21], Alternating Direction Method of Multipliers (ADMM) [9],
[18], Nesterov’s method [15], [17] and second-order algorithm [10], [23], with
different performances and restrictions. Among these types, DSD is the most
important algorithm because it is easily implemented in a distributed way (ADMM
needs sequential variable updates and second order methods need costly
distributed Hessian calculation), and the basis of many further developed
algorithms. For example, by adding history gradient information to DSD, the
methods in [13] and [16] can achieve a linear convergence rate for the sum of
strongly convex and smooth functions with a constant stepsize. Nesterov’s method
can also be considered as a variant of the gradient method. So in this paper, we
will focus on gradient-based algorithms.
</p>
</blockquote>

<p>
文章提出一套灵活的分布式次梯度(subgradient)算法，允许处理器通过基于概率地在多个正在进行的任务之间切换，从而同时处理多个正在进行的任务。
</p>
</div>
</div>

<div id="outline-container-org92e24bb" class="outline-3">
<h3 id="org92e24bb">什么是次梯度 <b>subgrdient</b></h3>
<div class="outline-text-3" id="text-org92e24bb">
<blockquote>
<p>
当函数不可导时，无法通过常规的方法求梯度，也就无法使用梯度下降发来进行实现优化算法，因此针对存在不可导（不光滑）的函数提出其次梯度的概念，其标准定义为：
</p>

<p>
g 是函数 f 在 x 点的次梯度，当
\[
    f(y) \geq f(x) + g^T(y-x), \forall y
\]
</p>

<p>
上面的 g 是一个可能的次梯度，函数在某一点的次梯度是一个集合被记为&part; f(x)，对于一个凸函数而言，其 &part; f(x) 非空。所以可以使用类似于经典梯度下降的方法使用次梯度对不可导函数进行优化。
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgc442247" class="outline-3">
<h3 id="orgc442247">符号规定：</h3>
<div class="outline-text-3" id="text-orgc442247">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">符号</th>
<th scope="col" class="org-left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(n\)</td>
<td class="org-left"><b>number</b> of processors</td>
</tr>

<tr>
<td class="org-left">\(x_i^k, y_i^k\)</td>
<td class="org-left"><b>value</b> of Processor i in iteration k</td>
</tr>

<tr>
<td class="org-left">\(a_{ij}^k\)</td>
<td class="org-left"><b>weight</b> of processor i put on value sent from j</td>
</tr>

<tr>
<td class="org-left">\(\partial f(x)\)</td>
<td class="org-left"><b>set</b> of <b>subgradient</b> of function at x</td>
</tr>

<tr>
<td class="org-left">\(\nabla f(x)\)</td>
<td class="org-left"><b>gradient</b> of f at x</td>
</tr>

<tr>
<td class="org-left">\(\Vert \cdot \Vert_p\)</td>
<td class="org-left">\(l_p - norm\) for vectors</td>
</tr>

<tr>
<td class="org-left">\(\pi \{x\}\)</td>
<td class="org-left">\(\pi \{x\} = \arg \min \limits_{y \in \chi} \Vert y-x \Vert_2^2\)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-org81a8392" class="outline-2">
<h2 id="org81a8392">模型与算法</h2>
<div class="outline-text-2" id="text-org81a8392">
</div>
<div id="outline-container-org2dcd96b" class="outline-3">
<h3 id="org2dcd96b">问题模型</h3>
<div class="outline-text-3" id="text-org2dcd96b">
<p>
考虑优化的问题与上面提到的分布式优化问题相似，这里再抄写一遍：
</p>
\begin{equation}
\min_\limits{m \in \chi} f(x) = \frac{1}{n} \sum_{i=1}^n f_i(x)
\end{equation}
<p>
其中 \(f_i(x)\) 对在 \(\chi\) 上的所以 i 都是凸的。网络是一个静态的无向图 \(G = (V,
\xi)\) ，每个处理器 \(process_i\) 仅能访问自己本地函数 \(f_i\) 并计算起次梯度，同时
\(Process_i\) 可以与邻居通信自己的值，邻居被记为 \(N(i)\) 。
</p>

<p>
计算次梯度需要的花费记为 1，在 1 条链路上两个处理器的产生的通信开销记为 \(\tau\) 
</p>
</div>
</div>

<div id="outline-container-org91b3c28" class="outline-3">
<h3 id="org91b3c28">算法</h3>
<div class="outline-text-3" id="text-org91b3c28">
<p>
对于一个有监督的分布式学习可以将每个处理器上的优化问题刻画为这个函数：
\(f_i(\theta) = l (h(x_i; \theta), y_i)\) ，其中 h 是预测函数，l 是损失函数， \(x_i,
y_i\) 是处理器 i 本地存储的数据集中的数据， &theta; 是希望全局优化的参数，下面给出三个假设：
</p>
<ul class="org-ul">
<li>\(f_i(x)\) 的次梯度是有界的；字面意思；
<ul class="org-ul">
<li>测试</li>
<li>测试第二遍</li>
<li>ceui</li>
</ul></li>
<li>\(f_i(x)\) 是 l 光滑的，(<i>Lipschitz smooth 利普希茨连续用来描述函数的平滑程度的，强调的是函数的梯度不会太突兀 L 是光滑程度，具体来说就是 x,y 两点的梯度差&lt;= L|x-y|.</i>)</li>
<li>\(f_i(x)\) 是 &mu; -strongly convex。</li>
</ul>

<p>
分布式优化的目标是用做少的通信开销使得每个处理器上的 \(x_i^k\) 收敛到(1)式的最优解。这里的一个重要想法就是能否一次今更新所有处理器的一个子集上的值，该子集外的处理器做其他任务并保持子集的值不变，能否也可以达到全局优化的目标。文章介绍了一个基于概率的部分更行的次梯度算法(PUSD)的算法如下：
</p>


<div class="figure">
<p><img src="/assets/blog/2020/03/15/flexible-distributed-optimization-framework/2020-03-17_21-18-10_Screen Shot 2020-03-17 at 21.18.06.png" alt="2020-03-17_21-18-10_Screen Shot 2020-03-17 at 21.18.06.png" />
</p>
</div>

<p>
其第 6-7 行是与其他主机交换信息的过程，第 8-13 行是根据概率选择是否计算次梯度以实现全局优化。
</p>
</div>
</div>
</div>

</div>
</div>

    <div>
      <div class="post-meta">
        <span title="post date" class="post-info">2020-03-15</span>
        <span title="last modification date" class="post-info">2020-03-17</span>
        <span title="tags" class="post-info"><a href="/tags/study/">Study</a>, <a href="/tags/infocom2019/">infocom2019</a></span>
        <span title="author" class="post-info">Layer 3</span>
      </div>
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
          //var disqus_developer = 1;
          var disqus_identifier = "/blog/2020/03/15/flexible-distributed-optimization-framework";
          var disqus_url = "http://ansont.cn/blog/2020/03/15/flexible-distributed-optimization-framework";
          var disqus_shortname = 'Layer 3';
          /* * * DON'T EDIT BELOW THIS LINE * * */
          (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
          })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
       <div id="hashover"></div>
       <script type="text/javascript" src="/hashover.php"></script>
       <noscript>You must have JavaScript enabled to use the comments.</noscript>
      </section>
      <script src="//code.jquery.com/jquery-latest.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/prettify.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="/media/js/main.js"></script>
      <div class="footer">
        <p>Generated by <a href="http://www.gnu.org/software/emacs/">Emacs</a> 28.x (<a href="http://orgmode.org">Org mode</a> 9.x)</p>
        <p>
          Copyright &copy; 2012 - <span id="footerYear"></span> <a href="mailto:weitang &lt;at&gt; mail &lt;dot&gt; ustc &lt;dot&gt; edu &lt;dot&gt; cn">Layer 3</a>
          &nbsp;&nbsp;-&nbsp;&nbsp;
          Powered by <a href="https://github.com/kelvinh/org-page" target="_blank">org-page</a>
          <script type="text/javascript">document.getElementById("footerYear").innerHTML = (new Date()).getFullYear();</script>
        </p>
      </div>
    </div>

  </body>
</html>
